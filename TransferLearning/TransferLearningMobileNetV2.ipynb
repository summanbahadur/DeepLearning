{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90b76d0",
   "metadata": {},
   "source": [
    "Assignment 7\n",
    "\n",
    "Name : Summan Bahadur\n",
    "Roll Number : MSDSF21M509\n",
    "\n",
    "Using MobileNetV2 , allready trained model for classification of MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8721896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu Epochs: 4 Batch size: 1000\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945666b03fbd4aa5af3f18f8536ca884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\raw\\train-images-idx3-ubyte.gz to data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07b8e265e79499a923919ad5df803e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\raw\\train-labels-idx1-ubyte.gz to data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e2167e9edc48f481f7cc71780a2367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ae2961427447e68fab2c53a87f94d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data/MNIST\\raw\n",
      "\n",
      "Length train: 60000 Length test: 10000\n",
      "Number of train batches: 60 Number of test batches: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Summan Bahadur\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Summan Bahadur\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\Summan Bahadur/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765193458f7e43c0b08a899bb50371a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.481981\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.348076\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.510171\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.103787\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.277915\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.111878\n",
      "\n",
      "Test set: Average loss: 0.0686, Accuracy: 9801/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.045531\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.037837\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.033032\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.091579\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.030533\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.025997\n",
      "\n",
      "Test set: Average loss: 0.0658, Accuracy: 9817/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.044595\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.016077\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.026977\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.023393\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.011292\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.022031\n",
      "\n",
      "Test set: Average loss: 0.0328, Accuracy: 9898/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.035126\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.007275\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.003731\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.004858\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.014533\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.010919\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 9920/10000 (99%)\n",
      "\n",
      "Submission saved in: submission.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    log_interval = 10\n",
    "    loss_func = CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.repeat(1, 3, 1, 1)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def tst(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    loss_func = CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.repeat(1, 3, 1, 1)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_func(output, target)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    batch_size = 1000\n",
    "    learning_rate = 1.0\n",
    "    reduce_lr_gamma = 0.7\n",
    "    epochs = 4\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('Device: {} Epochs: {} Batch size: {}'.format(device, epochs, batch_size))\n",
    "\n",
    "    kwargs = {'batch_size': batch_size}\n",
    "    if torch.cuda.is_available():\n",
    "        kwargs.update({'num_workers': 1, 'pin_memory': True})\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    dataset1 = datasets.MNIST('data/', train=True, download=True, transform=transform)\n",
    "    dataset2 = datasets.MNIST('data/', train=False, transform=transform)\n",
    "    print('Length train: {} Length test: {}'.format(len(dataset1), len(dataset2)))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset1, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, shuffle=False, **kwargs)\n",
    "    print('Number of train batches: {} Number of test batches: {}'.format(len(train_loader), len(test_loader)))\n",
    "\n",
    "    model = mobilenet_v2(pretrained=True)\n",
    "    model.classifier[1] = torch.nn.Linear(in_features=model.classifier[1].in_features, out_features=10)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=reduce_lr_gamma)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        tst(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "    # Final prediction\n",
    "    ids = list(range(len(dataset2)))\n",
    "    submission = pd.DataFrame(ids, columns=['id'])\n",
    "    predictions = []\n",
    "    real = []\n",
    "    for data, target in test_loader:\n",
    "        data = data.repeat(1, 3, 1, 1)\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        predictions += list(pred.cpu().numpy()[:, 0])\n",
    "        real += list(target.numpy())\n",
    "    submission['pred'] = predictions\n",
    "    submission['real'] = real\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print('Submission saved in: {}'.format('submission.csv'))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf48444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
